{"code":"import { __assign, __awaiter, __generator } from \"tslib\";\r\nimport { max_video_config } from './resolution.js';\r\nimport { WebMWriter } from './webm-writer.js';\r\nfunction onerror(e) {\r\n    console.error(e);\r\n}\r\nvar video_track;\r\nvar audio_track;\r\nvar video_readable;\r\nvar audio_readable;\r\nvar video_settings;\r\nvar audio_settings;\r\nvar writer;\r\n// See https://www.webmproject.org/vp9/mp4/\r\n// and also https://googlechrome.github.io/samples/media/vp9-codec-string.html\r\n//以下是vp9的codec设置\r\nvar vp9_params = {\r\n    profile: 0,\r\n    level: 10,\r\n    bit_depth: 8,\r\n    //fixed 1\r\n    chroma_subsampling: 1\r\n    // chroma_subsampling: chroma_el.value ? 2 : 1\r\n};\r\nvar vp9c = Object.fromEntries(Object.entries(vp9_params).map(function (_a) {\r\n    var k = _a[0], v = _a[1];\r\n    return [k, v.toString().padStart(2, '0')];\r\n}));\r\n//这里的chroma_subsampling也许是要根据输入来确定？\r\nvar vp9_codec = \"vp09.\".concat(vp9c.profile, \".\").concat(vp9c.level, \".\").concat(vp9c.bit_depth, \".\").concat(vp9c.chroma_subsampling); //vp09.00.10.08.01\r\n// See https://github.com/ietf-wg-cellar/matroska-specification/blob/master/codec/av1.md\r\n// and also https://aomediacodec.github.io/av1-isobmff/#codecsparam\r\n//以下是av1的codec设置\r\nvar av1_params = {\r\n    profile: 0,\r\n    level: 0,\r\n    tier: 0,\r\n    high_bitdepth: 0,\r\n    twelve_bit: false,\r\n    monochrome: false,\r\n    chroma_subsampling_x: 0,\r\n    chroma_subsampling_y: 0,\r\n    // chroma_subsampling_x: !!chroma_el.value,\r\n    // chroma_subsampling_y: !!chroma_el.value,\r\n    chroma_sample_position: 0\r\n};\r\nvar av1_bitdepth = 8 + av1_params.high_bitdepth * (av1_params.profile === 2 && av1_params.twelve_bit ? 4 : 2);\r\nvar av1_codec = \"av01.\".concat(av1_params.profile, \".\").concat(av1_params.level.toString().padStart(2, '0')).concat(av1_params.tier === 0 ? 'M' : 'H', \".\").concat(av1_bitdepth.toString().padStart(2, '0'), \".\").concat(av1_params.chroma_subsampling_x + 0).concat(av1_params.chroma_subsampling_y + 0).concat(av1_params.chroma_sample_position); //.${av1_params.chroma_subsampling_x+0}${av1_params.chroma_subsampling_y+0}${av1_params.chroma_sample_position}`;\r\n//这个是encoder的config，应该整体传入encode方法\r\nvar encoder_constraints = {\r\n    //codec: 'avc1.42E01E',\r\n    // codec: codec === 'av01' ? av1_codec : vp9_codec,\r\n    codec: av1_codec,\r\n    //width应该和原来的width相同，但是这里先写死成640\r\n    width: 640,\r\n    //height应该和原来的height相同，但是这里先写死成360\r\n    height: 360,\r\n    bitrate: 2500 * 1000,\r\n    //framerate应该和原来的framerate相同，但是这里先写死成30\r\n    framerate: 30,\r\n    latencyMode: 'realtime'\r\n};\r\nvar video_worker = new Worker('./worker/encoder-worker.js');\r\nvideo_worker.onerror = onerror;\r\nvideo_worker.onmessage = relay_data;\r\nvar audio_worker = new Worker('./worker/encoder-worker.js');\r\naudio_worker.onerror = onerror;\r\naudio_worker.onmessage = relay_data;\r\nvar num_exits = 0;\r\nvar video_encoder_config;\r\nfunction relay_data(ev) {\r\n    var msg = ev.data;\r\n    switch (msg.type) {\r\n        case 'error':\r\n            onerror(msg.detail);\r\n            break;\r\n        case 'exit':\r\n            if (++num_exits === 2) {\r\n                webm_worker.postMessage({ type: 'end' });\r\n            }\r\n            break;\r\n        default:\r\n            webm_worker.postMessage(msg, [msg.data]);\r\n            break;\r\n    }\r\n}\r\n//主要需要改动的地方是这些。。他们使用message相互交互\r\nvar webm_worker = new Worker('./webm-worker.js');\r\nwebm_worker.onerror = onerror;\r\nwebm_worker.onmessage = function (ev) { return __awaiter(void 0, void 0, void 0, function () {\r\n    var msg, _a, r;\r\n    return __generator(this, function (_b) {\r\n        switch (_b.label) {\r\n            case 0:\r\n                msg = ev.data;\r\n                _a = msg.type;\r\n                switch (_a) {\r\n                    case 'exit': return [3 /*break*/, 1];\r\n                    case 'start-stream': return [3 /*break*/, 3];\r\n                    case 'muxed-data': return [3 /*break*/, 4];\r\n                    case 'stats': return [3 /*break*/, 6];\r\n                    case 'error': return [3 /*break*/, 7];\r\n                }\r\n                return [3 /*break*/, 8];\r\n            case 1:\r\n                if (msg.code !== 0) {\r\n                    onerror(new ErrorEvent('muxer exited with status ${msg.code}'));\r\n                }\r\n                webm_worker.terminate();\r\n                video_worker.terminate();\r\n                audio_worker.terminate();\r\n                exited = true;\r\n                return [4 /*yield*/, writer.finish()];\r\n            case 2:\r\n                r = _b.sent();\r\n                //这一块直接用log输出\r\n                // rec_info.innerText = `Finished: Duration ${writer.duration}ms, Size ${writer.size} bytes`;\r\n                console.log(\"Finished: Duration \".concat(writer.duration, \"ms, Size \").concat(writer.size, \" bytes\"));\r\n                console.log(\"Filename \".concat(writer.name, \", Cues at \").concat(r ? 'start' : 'end'));\r\n                // //这里是如果选中了in-memory button\r\n                // if (inmem_el.checked) {\r\n                //     const blob = new Blob(r, { type: 'video/webm' });\r\n                //     const a = document.createElement('a');\r\n                //     const filename = 'camera.webm';\r\n                //     a.textContent = filename;\r\n                //     a.href = URL.createObjectURL(blob);\r\n                //     a.download = filename;\r\n                //     document.body.appendChild(a);\r\n                //     a.click();\r\n                //     document.body.removeChild(a);\r\n                // } else {\r\n                //     //这句被我提出来了\r\n                //console.log(`Filename ${writer.name}, Cues at ${r ? 'start' : 'end'}`);\r\n                // }\r\n                // }\r\n                return [3 /*break*/, 8];\r\n            case 3:\r\n                //under start-stream ,main thread post message to video_worker&audio_worker\r\n                video_worker.postMessage({ message: {\r\n                        type: 'start',\r\n                        readable: video_readable,\r\n                        key_frame_interval: key_frame_interval,\r\n                        config: video_encoder_config\r\n                    }, transferable: [video_readable] });\r\n                audio_worker.postMessage({ message: {\r\n                        type: 'start',\r\n                        audio: true,\r\n                        readable: audio_readable,\r\n                        config: {\r\n                            // codec: pcm_el.checked ? 'pcm' : 'opus',\r\n                            codec: 'opus',\r\n                            bitrate: 128 * 1000,\r\n                            sampleRate: audio_settings.sampleRate\r\n                        }\r\n                    }, transferable: [audio_readable] });\r\n                return [3 /*break*/, 8];\r\n            case 4: \r\n            // if (record_el.checked) {\r\n            return [4 /*yield*/, writer.write(msg.data)];\r\n            case 5:\r\n                // if (record_el.checked) {\r\n                _b.sent();\r\n                console.log(\"Recorded \".concat(writer.size, \" bytes\"));\r\n                // }\r\n                queue.push(msg.data);\r\n                // if (!pcm_el.checked) {\r\n                //     remove_append();\r\n                // }\r\n                return [3 /*break*/, 8];\r\n            case 6:\r\n                console.log(msg.data);\r\n                return [3 /*break*/, 8];\r\n            case 7:\r\n                onerror(msg.detail);\r\n                return [3 /*break*/, 8];\r\n            case 8: return [2 /*return*/];\r\n        }\r\n    });\r\n}); };\r\nexport function beginEncode(mediaStream) {\r\n    return __awaiter(this, void 0, void 0, function () {\r\n        var ex_1;\r\n        return __generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    video_track = mediaStream.getVideoTracks()[0];\r\n                    audio_track = mediaStream.getAudioTracks()[0];\r\n                    video_readable = (new MediaStreamTrackProcessor({ track: video_track })).readable;\r\n                    audio_readable = (new MediaStreamTrackProcessor({ track: audio_track })).readable;\r\n                    video_settings = video_track.getSettings();\r\n                    console.log(\"video resolution: \".concat(video_settings.width, \"x\").concat(video_settings.height));\r\n                    console.log(\"encoder resolution: \".concat(video_encoder_config === null || video_encoder_config === void 0 ? void 0 : video_encoder_config.width, \"x\").concat(video_encoder_config === null || video_encoder_config === void 0 ? void 0 : video_encoder_config.height));\r\n                    audio_settings = audio_track.getSettings();\r\n                    return [4 /*yield*/, getVideoConfig()];\r\n                case 1:\r\n                    _a.sent();\r\n                    writer = new WebMWriter();\r\n                    _a.label = 2;\r\n                case 2:\r\n                    _a.trys.push([2, 4, , 5]);\r\n                    //这里直接给camera.webm，也就是采用disk的方式运行\r\n                    return [4 /*yield*/, writer.start('camera.webm')];\r\n                case 3:\r\n                    //这里直接给camera.webm，也就是采用disk的方式运行\r\n                    _a.sent();\r\n                    return [3 /*break*/, 5];\r\n                case 4:\r\n                    ex_1 = _a.sent();\r\n                    throw ex_1;\r\n                case 5:\r\n                    start();\r\n                    return [2 /*return*/];\r\n            }\r\n        });\r\n    });\r\n}\r\n// let video_track, audio_track;\r\nfunction getVideoConfig() {\r\n    return __awaiter(this, void 0, void 0, function () {\r\n        var _a;\r\n        return __generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0: return [4 /*yield*/, max_video_config(__assign(__assign({}, encoder_constraints), { \r\n                        //ratio应该是用原来的数据进行运算，但是这里先写死\r\n                        // ratio: 640 / 360\r\n                        ratio: video_settings.width / video_settings.height }))];\r\n                case 1:\r\n                    _a = (_b.sent());\r\n                    if (_a) return [3 /*break*/, 3];\r\n                    return [4 /*yield*/, max_video_config(encoder_constraints)];\r\n                case 2:\r\n                    _a = (_b.sent());\r\n                    _b.label = 3;\r\n                case 3:\r\n                    //这个config应该是上层传下来的参数，如果只是做演示，可以写死？\r\n                    video_encoder_config = _a;\r\n                    return [2 /*return*/];\r\n            }\r\n        });\r\n    });\r\n}\r\n// const stream = await navigator.mediaDevices.getUserMedia({\r\n//     audio: {\r\n//       echoCancellation: false,\r\n//       channelCount: 2\r\n//     },\r\n//     video: {\r\n//         width: 4096,\r\n//         height: 2160,\r\n//         frameRate: {\r\n//             ideal: 30,\r\n//             max: 30\r\n//         }\r\n//     }\r\n// });\r\n//应该是用原来的数据进行log，但是这里先注释\r\nvar exited = false;\r\nvar queue = [];\r\nvar key_frame_interval = 1;\r\n//这个start需要靠别的地方调用了，也许暴露出来的就是start，codec_id等传入进来\r\nfunction start() {\r\n    //这里需要改，连带着webm_worker，和code_worker也需要改\r\n    webm_worker.postMessage({\r\n        type: 'start',\r\n        webm_stats_interval: 1000,\r\n        //webm_receiver: './test-receiver.js',\r\n        webm_metadata: {\r\n            max_cluster_duration: BigInt(2000000000),\r\n            video: __assign({ width: video_encoder_config === null || video_encoder_config === void 0 ? void 0 : video_encoder_config.width, height: video_encoder_config === null || video_encoder_config === void 0 ? void 0 : video_encoder_config.height, \r\n                //video_settings从video_track而来\r\n                frame_rate: video_settings.frameRate, \r\n                //codec_id: 'V_MPEG4/ISO/AVC'\r\n                //等待修改：这里先写死成V_AV1\r\n                // codec_id: codec === 'av01' ? 'V_AV1' : 'V_VP9',\r\n                codec_id: 'V_AV1' }, (av1_params)\r\n            // ...(codec === 'av01' ? av1_params : vp9_params)\r\n            ),\r\n            audio: {\r\n                // bit_depth: pcm_el.checked ? 32 : 0,\r\n                bit_depth: 0,\r\n                //audio_settings从audio_track而来\r\n                sample_rate: audio_settings.sampleRate,\r\n                // 报错audio_settings没有channelcount\r\n                // channels: audio_settings.channelCount,\r\n                // codec_id: pcm_el.checked ? 'A_PCM/FLOAT/IEEE' : 'A_OPUS'\r\n                codec_id: 'A_OPUS'\r\n            }\r\n        }\r\n    });\r\n}\r\n//媒体资源对象接口\r\n// const source = new MediaSource();\r\n//Fired when the MediaSource instance has been opened by a media element \r\n// and is ready for data to be appended to the SourceBuffer objects in sourceBuffers.\r\n// source.addEventListener('sourceopen', function () {\r\n//     //source represents a chunk of media to be passed into an HTMLMediaElement and played, via a MediaSource object. \r\n//     buffer = this.addSourceBuffer(`video/webm; codecs=${codec === 'av01' ? av1_codec : vp9_codec},opus`);\r\n//     //updateend: Fired after SourceBuffer.appendBuffer() or SourceBuffer.remove() ends. This event is fired after update.\r\n//     //update: Fired whenever SourceBuffer.appendBuffer() or SourceBuffer.remove() completes. \r\n//     //SourceBuffer.updating changes from true to false. This event is fired before updateend.\r\n//     buffer.addEventListener('updateend', remove_append);\r\n//     start();\r\n// });\r\n","references":["/home/wudi/desktop/code/ts/vue3/vite-ts-test/web/packages/poco-codec/src/codec/resolution.ts","/home/wudi/desktop/code/ts/vue3/vite-ts-test/web/packages/poco-codec/src/codec/webm-writer.ts"]}
